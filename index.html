<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ASL Keypoint Recognition</title>
    <!-- 1. Tailwind CSS for UI -->
    <script src="https://cdn.tailwindcss.com"></script>
    
    <style>
        /* 2. Import Google Font */
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700;900&display=swap');
        
        body { font-family: 'Inter', sans-serif; overflow: hidden; }
        
        /* 3. Style for the hand skeleton */
        .hand-landmark { fill: #FF0000; stroke: #FFFFFF; stroke-width: 4px; }
        .hand-connection { stroke: #00FF00; stroke-width: 6px; }
    </style>
</head>
<body class="bg-gray-900 text-gray-100 flex flex-col md:flex-row items-center justify-center min-h-screen p-4 md:p-8">

    <!-- Left Column: Video Feed & Title -->
    <div class="w-full max-w-3xl md:mr-8">
        <h1 class="text-3xl md:text-4xl font-bold text-center text-cyan-400 mb-4">ASL Alphabet Recognition</h1>
        
        <!-- Loading State -->
        <div id="loading-container" class="flex flex-col items-center justify-center bg-gray-800 rounded-2xl shadow-xl h-96">
            <div class="text-2xl font-semibold text-gray-300" id="loading-text">Initializing Hand Tracker...</div>
            <div class="mt-4 w-12 h-12 border-4 border-t-cyan-400 border-gray-600 rounded-full animate-spin"></div>
            <div id="server-status" class="text-lg text-yellow-400 mt-4">Waiting for server...</div>
        </div>

        <!-- Video Container -->
        <div id="video-container" class="relative rounded-2xl overflow-hidden shadow-xl hidden" style="aspect-ratio: 4/3;">
            <video id="webcam" class="w-full h-full object-cover transform -scale-x-100" autoplay playsinline></video>
            <canvas id="output-canvas" class="absolute top-0 left-0 w-full h-full transform -scale-x-100"></canvas>
        </div>
         <div class="flex justify-center space-x-4 mt-4">
            <button id="start-btn" class="px-6 py-3 bg-cyan-500 text-gray-900 font-bold rounded-lg shadow-lg hover:bg-cyan-400 transition duration-300" disabled>Start Camera</button>
            <button id="stop-btn" class="px-6 py-3 bg-gray-600 text-white font-bold rounded-lg shadow-lg hover:bg-gray-500 transition duration-300 hidden">Stop Camera</button>
        </div>
    </div>

    <!-- Right Column: Prediction Output -->
    <div class="w-full max-w-xs md:max-w-sm mt-6 md:mt-0">
        <div class="bg-gray-800 rounded-2xl shadow-xl p-6 text-center">
            <div class="text-lg font-semibold text-gray-400 mb-2">PREDICTION</div>
            <div id="prediction-text" class="text-8xl md:text-9xl font-black text-cyan-400 h-28 md:h-32 flex items-center justify-center">
                ---
            </div>
            <div class="text-sm text-gray-500 mt-2">Confidence</div>
            <div id="confidence-bar" class="w-full bg-gray-700 rounded-full h-2.5 mt-1">
                <div id="confidence-fill" class="bg-cyan-400 h-2.5 rounded-full transition-all duration-300" style="width: 0%"></div>
            </div>
        </div>
    </div>

    <!-- Main Application Logic -->
    <script type="module">
        // --- FIX: Corrected the import path to the stable CDN endpoint ---
        import { HandLandmarker, FilesetResolver, DrawingUtils } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js";

        // --- DOM Elements ---
        const video = document.getElementById("webcam");
        const canvas = document.getElementById("output-canvas");
        const ctx = canvas.getContext("2d");
        const loadingText = document.getElementById("loading-text");
        const serverStatus = document.getElementById("server-status");
        const videoContainer = document.getElementById("video-container");
        const loadingContainer = document.getElementById("loading-container");
        const predictionText = document.getElementById("prediction-text");
        const confidenceFill = document.getElementById("confidence-fill");
        const startBtn = document.getElementById("start-btn");
        const stopBtn = document.getElementById("stop-btn");

        // --- Globals ---
        const FLASK_SERVER_URL = "http://127.0.0.1:5000/predict";
        let handLandmarker;
        let predictionBuffer = [];
        const SMOOTHING_BUFFER_SIZE = 10;
        let predictLoopId; // Use this to control the requestAnimationFrame loop
        let drawingUtils; // To draw the hand

        // --- Helper: Normalize Keypoints (Python Logic) ---
        function normalizeLandmarks(landmarks) {
            let coords = [];
            for (const landmark of landmarks) {
                coords.push(landmark.x, landmark.y, landmark.z);
            }
            coords = new Float32Array(coords); // 63 elements

            const root = [coords[0], coords[1], coords[2]];
            for (let i = 0; i < 21; i++) {
                coords[i * 3]     -= root[0]; // x
                coords[i * 3 + 1] -= root[1]; // y
                coords[i * 3 + 2] -= root[2]; // z
            }

            const middleFingerBase = [coords[9 * 3], coords[9 * 3 + 1], coords[9 * 3 + 2]];
            const scaleFactor = Math.sqrt(
                middleFingerBase[0] ** 2 + middleFingerBase[1] ** 2 + middleFingerBase[2] ** 2
            );
            if (scaleFactor === 0) return null;

            for (let i = 0; i < 63; i++) {
                coords[i] /= scaleFactor;
            }
            return Array.from(coords); // Convert to simple array for JSON
        }
        
        // --- Helper: Smoothing Logic ---
        function applySmoothing(prediction) {
            predictionBuffer.push(prediction);
            if (predictionBuffer.length > SMOOTHING_BUFFER_SIZE) {
                predictionBuffer.shift(); 
            }
            const counts = {};
            let maxCount = 0;
            let mode = "---";
            for (const pred of predictionBuffer) {
                if (pred === null) continue;
                counts[pred] = (counts[pred] || 0) + 1;
                if (counts[pred] > maxCount) {
                    maxCount = counts[pred];
                    mode = pred;
                }
            }
            return mode;
        }

        // --- Main Prediction Loop ---
        async function predictWebcam() {
            if (!video.srcObject) {
                 // Stop loop if video is off
                return;
            }

            const startTimeMs = performance.now();
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            // Ensure handLandmarker is ready before detecting
            if (handLandmarker) {
                const results = handLandmarker.detectForVideo(video, startTimeMs);

                let smoothedPrediction = "---";
                let confidence = 0;

                if (results.landmarks && results.landmarks.length > 0) {
                    const landmarks = results.landmarks[0];
                    
                    // Draw skeleton
                    drawingUtils.drawConnectors(landmarks, HandLandmarker.HAND_CONNECTIONS, { color: '#00FF00', lineWidth: 6 });
                    drawingUtils.drawLandmarks(landmarks, { color: '#FF0000', lineWidth: 4 });
                    
                    const features = normalizeLandmarks(landmarks);
                    
                    if (features) {
                        // *** Send features to Python server ***
                        try {
                            const response = await fetch(FLASK_SERVER_URL, {
                                method: 'POST',
                                headers: { 'Content-Type': 'application/json' },
                                body: JSON.stringify({ features: features })
                            });
                            if (response.ok) {
                                const res = await response.json();
                                confidence = res.confidence;
                                smoothedPrediction = applySmoothing(res.prediction);
                            } else {
                               smoothedPrediction = applySmoothing(null); 
                            }
                        } catch (e) {
                             smoothedPrediction = applySmoothing(null);
                             // If server is down, show it
                             serverStatus.textContent = "Server Connection Lost!";
                             serverStatus.classList.remove("text-green-400");
                             serverStatus.classList.add("text-red-500");
                        }
                    }
                } else {
                    smoothedPrediction = applySmoothing(null);
                }

                predictionText.textContent = smoothedPrediction;
                confidenceFill.style.width = `${confidence * 100}%`;
            }
            
            // Keep the loop going
            predictLoopId = window.requestAnimationFrame(predictWebcam);
        }
        
        // --- Setup Functions ---
        startBtn.addEventListener('click', async () => {
            loadingText.textContent = "Starting camera...";
            videoContainer.classList.remove("hidden");
            loadingContainer.classList.add("hidden");

            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: "user", width: { ideal: 640 }, height: { ideal: 480 } },
                    audio: false
                });
                video.srcObject = stream;
                
                video.onloadedmetadata = () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    startBtn.classList.add("hidden");
                    stopBtn.classList.remove("hidden");
                    // Start the prediction loop
                    predictWebcam();
                };
            } catch (err) {
                console.error("Error starting webcam:", err);
                loadingText.textContent = "Error: Webcam access denied.";
                videoContainer.classList.add("hidden");
                loadingContainer.classList.remove("hidden");
            }
        });
        
        stopBtn.addEventListener('click', () => {
            if (predictLoopId) {
                window.cancelAnimationFrame(predictLoopId);
                predictLoopId = null;
            }
            if (video.srcObject) {
                video.srcObject.getTracks().forEach(track => track.stop());
                video.srcObject = null;
            }
            videoContainer.classList.add("hidden");
            loadingContainer.classList.remove("hidden");
            loadingText.textContent = "Camera off. Ready to start.";
            predictionText.textContent = "---";
            confidenceFill.style.width = "0%";
            startBtn.classList.remove("hidden");
            stopBtn.classList.add("hidden");
        });

        async function main() {
            // 1. Check if Python server is running
            try {
                // --- FIX: Ping the root URL, not the /predict endpoint ---
                await fetch("http://127.0.0.1:5000/"); 
                serverStatus.textContent = "Server Connected!";
                serverStatus.classList.remove("text-yellow-400");
                serverStatus.classList.add("text-green-400");
            } catch(e) {
                serverStatus.textContent = "Error: Python server is not running!";
                serverStatus.classList.remove("text-yellow-400");
                serverStatus.classList.add("text-red-500");
                loadingText.textContent = "Please run 'python app.py' first.";
                return;
            }

            // 2. Create Hand Landmarker
            try {
                const vision = await FilesetResolver.forVisionTasks(
                    "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.14/wasm"
                );
                handLandmarker = await HandLandmarker.createFromOptions(vision, {
                    baseOptions: {
                        modelAssetPath: `https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task`,
                        delegate: "GPU",
                    },
                    runningMode: "VIDEO",
                    numHands: 1,
                    minHandDetectionConfidence: 0.7, // Higher confidence for detection
                    minHandTrackingConfidence: 0.5
                });
                
                // Init the drawing utility
                drawingUtils = new DrawingUtils(ctx);
                
                loadingText.textContent = "Ready to Start!";
                startBtn.disabled = false;
            } catch (e) {
                console.error("Error creating Hand Landmarker:", e);
                loadingText.textContent = "Error loading MediaPipe model.";
                serverStatus.textContent = "Page reload required.";
                serverStatus.classList.add("text-red-500");
            }
        }

        // Start the main setup process
        main();
    </script>
</body>
</html>